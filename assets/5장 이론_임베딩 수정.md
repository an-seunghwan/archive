# 차원 축소와 데이터 복원

## 1. 목적 

### 1. 저장 공간의 감소
- 용량이 큰 고차원 데이터를 저차원 데이터로 변환하여 저장함으로써, 데이터의 저장 공간을 감소시킬 수 있다.
### 2. 용이한 데이터 해석
- 주어진 고차원 데이터의 상태에서는 잘 구분되지 않던 데이터가 차원축소를 수행하면 저차원 공간에서 쉽게 구분될 수 있다. 
- 고차원 데이터는 시각화를 통해 해당 데이터들의 분포를 확인하기가 어렵다. 이런 경우에 차원 축소를 수행하면 저차원 공간에서 한눈에 알아볼 수 있는 시각화가 가능하고, 추가적으로 같은 라벨을 갖는 데이터끼리 그룹지어 해석할 수 있다는 장점이 있다.

## 2. 방법

### 1. 개념
- 고차원 데이터의 차원 축소 후의 결과를 임베딩(embedding)이라고 한다.
- 고차원 데이터의 저차원 공간으로의 임베딩이 잘 되었는지 판단할 때는, **해당 임베딩을 이용해 다시 원래의 데이터로 잘 복원할 수 있는지 여부**를 이용해 판단한다. 
- 즉, 임베딩이 주어진 데이터의 정보를 얼마나 충분히 담고 있는지를 이용해 차원 축소가 잘 되었는지를 판단하게 된다.

<img src="https://github.com/an-seunghwan/archive/blob/main/assets/dimreduction.png?raw=true" width="400">

### 2. 목표
- 위 그림에서 주어진 데이터가 $x$, 임베딩이 $z$, 그리고 복원된 데이터를 $\hat{x}$라고 할 수 있다.
- 여기서 $x$를 $z$로 바꿔주는 함수가 $f$, $z$를 $\hat{x}$로 바꿔주는 함수를 $g$라고 하자.
- **복원이 잘 되었는지를 평가하기위해 일정한 기준**이 필요한데, 주어진 데이터 $x$와 복원된 데이터 $\hat{x}$ 사이의 거리 $d(x, \hat{x})$를 정의하여 해당 **거리가 가까우면** 복원이 잘 되었다고 판단한다. 
- 따라서, 차원 축소는 주어진 모든 데이터 $x$들에 대해서 $d(x, \hat{x})$를 **최소화**하는 $f, g$를 찾는 문제라고 정의할 수 있다.
- (종류) 함수 $f, g$가 선형함수(단순한 함수)면 주성분 분석(Principal component analysis, PCA) 그리고 비선형함수(조금 더 복잡한 함수)이면 Restricted Boltzmann Machine (RBM) 또는 신경망 모형의 오토인코더(AutoEncoder) 등의 예시가 있다.
    - RBM에서는 $x$를 visible unit, $z$를 hidden unit이라고 부른다.

## 예시) 주성분 분석 

<img src="https://upload.wikimedia.org/wikipedia/commons/1/15/GaussianScatterPCA.png" width="400">

- 위 그림은 2차원 공간상에 분포해있는 2차원 데이터의 예시이다. 해당 데이터가 퍼져있는 전체적인 형태는 그림에 표시된 화살표 2개를 이용해 충분히 표현이 가능한데, 고차원 데이터에 대해서 이러한 화살표를 찾는 작업이 주성분 분석의 메인 아이디어라고 할 수 있다.

### 주성분 분석 활용 예시: 서울집 구별 집 가격의 주성분 분석
- 데이터: 서울시 구별 집 가격 데이터
- 설명변수: 집의 넓이, 방의 개수, 지어진 연도, 도심지로부터의 거리, 집이 속한 구의 범죄율 등
- 관심변수: 집 가격

1. 고차원 설명변수들로 구성된 관측치들을 주성분 분석을 이용해 2차원의 저차원 데이터로 요약
2. 2차원 공간상에서 차원축소된 저차원 관측치들을 주성분 축을 따라서 시각화
3. 주성분의 값에 따라 관측치들의 집 가격이 어떻게 분포해 있는지를 확인
4. 주성분을 활용하여, 각각의 설명변수들이 집 가격 형성에 미치는 영향(예. 양/음의 관계) 파악